
\section{Introduction}

In ordinary intuitionistic logic or $\lambda$-calculus, assumptions or
variables can go unused (weakening), be used in any order (exchange), be
used more than once (contraction), and be used in any position in a
term.  \emph{Substructural} logics, such as linear logic, ordered logic,
relevant logic, and affine logic, omit some of these structural
properties of weakening, exchange, and contraction, while \emph{modal
  logics} place restrictions on where variables may be used---e.g. a
formula $\Bx{} C$ can only be proved using assumptions of $\Bx{} A$,
while an assumption of $\Dia{}{A}$ can only be used when the conclusion
is $\Dia{}{C}$.  Substructural and modal logics have had many
applications to both functional and logic programming (modeling concepts
such state, staging, distribution, and concurrency, to name just a few).
They are also used as \emph{internal languages} of categories: one uses
an appropriate logical language to do constructions ``inside'' a
particular mathematical setting, which often leads to shorter statements
than working ``externally''.  For example, to define a function
externally in domains, one must first define the underlying
set-theoretic function, and then prove that it is continuous; but when
using untyped $\lambda$-calculus as an internal language of domains,
there is no need to prove that a function described by a $\lambda$-term
is continuous, because all terms are shown to denote continuous
functions.  Substructural logics extend this idea to
various forms of monoidal categories, while modal logics describe monads
and comonads.  Recently,
\citet{schreibershulman12cohesive,shulman15realcohesion} proposed using
modal operators to add a notion of \emph{cohesion} to homotopy type
theory/univalent foundations~\citep{voevodsky06homotopy,uf13hott-book}.
Without going into the precise details of this application, the idea is
to add a triple $\sh{} \la \Flat{} \la \Sharp{}$ of type operators,
where for example $\Sharp{}$ is a monad (like a modal possibility
$\Diamond$ or $\bigcirc$), $\Flat{}$ is a comonad (like a modal
necessity $\Box$), and there is an adjunction structure between them
(e.g. $\flat{A} \to B$ is the same as $A \to \Sharp{B}$).  This raised
the question of how to best add modalities with these properties to type
theory.

Because other similar applications have different monads and comonads
with different properties, we would like general tools for going from a
semantic situation of interest to a well-behaved logic/type theory for
it, e.g. one with cut and identity admissibility (normalization,
$\eta$-expansion).  In previous work~\citep{ls16adjoint}, we considered
the special case of a single-assumption logic, building most directly on
the adjoint logics of
\citet{benton94mixed,bentonwadler96adjoint,reed09adjoint}.  Here we
extend this previous work to the multi-assumption case.  The resulting
framework is quite general and covers many existing intuitionistic
substructural and modal connectives: cartesian, linear, affine,
relevant, ordered, bunched~\citep{ohearnpym99bunched} and
non-associative products and implications; $n$-linear
variables~\citep{reed08namessubstructural,abel15modal,mcbride16nuttin};
the comonadic $\Box$ and linear exponential $!$ and
subexponentials~\citep{nigammiller09subexponentials,danos+93subexponentials};
monadic $\Diamond$ and $\bigcirc$ modalities; and adjoint logic $F$ and
$G$~\citep{benton94mixed,bentonwadler96adjoint,reed09adjoint}, including
the single-assumption 2-categorical version from our previous
work~\citep{ls16adjoint}.  It also supports variations on these, such as
non-monoidal comonads and non-strong monads.  A central syntactic result
is that cut and identity are admissible for our framework
itself, which implies cut admissibility for any logic that can be
described in the framework, including all of the above, as well as any
new logics that one designs using it.  When we view the derivations in
the framework as terms in a type theory, this gives an immediate
normalization (and $\eta$-expansion) result.
%% While it is not too surprising
%% that this is possible, given that cut proofs for these logics all follow
%% a similar template, it is nonetheless satisfying to codify this pattern
%% as an abstraction.

At a high level, the framework is based on the idea that all of the
above logics / type theories are a restriction on how variables can be
used in ordinary structural/cartesian proofs.  We express these
restrictions using a first layer, which is a simple type theory for what
we will call \emph{modes} and \emph{context descriptors}.  The modes are
just a collection of base types, which we write as $p,q,r$, while a
context descriptor $\alpha$ is a term built from variables and
constants.  The next layer is the main logic.  Each proposition/type is
assigned a mode, and the basic sequent is \seq{x_1 : A_1, \ldots, x_n :
  A_n}{\alpha}{C}, where if $A_i$ has mode $p_i$, and $C$ has mode $q$,
then $\oftp{x_1 : p_1,\ldots, x_n : p_n}{\alpha}{q}$.  We use a sequent
calculus to concisely describe cut-free derivations/normal forms, but
everything can be translated to natural deduction in the usual way.
$\Gamma$ itself behaves like an ordinary structural/cartesian context,
while the substructural and modal aspects are enforced by the
\emph{term} $\alpha$, which constrains how the resources from $\Gamma$
may be used.  For example, in linear logic/ordered logic/BI, the context
is usually taken to be a multiset/list/tree.  We represent this by a
pair of an ordinary structural context $\Gamma$, together with a term
$\alpha$ that describes the multiset or list or tree structure, labeled
with variables from the ordinary context at the leaves.  We pronounce a
sequent \seq{\Gamma}{\alpha}{A} as ``$\Gamma$ proves $A$ \{along,over\}
$\alpha$''.

For example, suppose we have one mode $\dsd{n}$, together with a context
descriptor constant $x : \dsd{n}, y:\dsd{n} \vdash x \odot y : \dsd{n}$.
Then an example sequent \seq{x:A, y:B, z:C, w:D}{(y \odot x) \odot z}{E}
should be read as saying that we must prove $E$ using the resources $y$
and $x$ and $z$ (but not $w$) according to the particular tree structure
${(y \odot x) \odot z}$.  If we say nothing else, the framework will
treat $\odot$ as describing a non-associative, linear, ordered context
as in Lambek calculus~\citep{lambek58calculus}: if we have a
product-like type $A \odot B$ internalizing this context
operation,\footnote{We overload binary operations to refer both to
  context descriptors and propositional connectives, because it is clear
  from whether it is applied to variables $x,y,z$ or propositions
  $A,B,C$ which we mean.}  then we will \emph{not} be able to prove
associativity ($(A \odot B) \odot C \dashv\vdash A \odot (B \odot C)$)
or exchange ($A \odot B \vdash B \odot A$) etc.  
\ifthenelse{\boolean{short}}{}{ 
%% para break
}
To get from this basic structure to a linear or affine or relevant or
cartesian system, we provide a way to add structural properties governing
the context descriptor term $\alpha$.  We analyze structural properties
as \emph{equations}, or more generally \emph{directed transformations},
on such terms.  For example, to specify linear logic, we will add a unit
element $1 : \dsd{n}$ together with equations making $(\odot,1)$ into a
commutative monoid ($x \odot (y \odot z) = (x \odot y) \odot z$ and 
$x \odot 1 = x = 1 \odot x$ and 
$x \odot y = y \odot x$)
so that the context descriptors ignore associativity and order.  To get
BI, we add an additional commutative monoid $(\times,\top)$ (with
weakening and contraction, as discussed below), so that a BI context
tree $(x:A,y:B);(z:C,w:D)$ can be represented by the ordinary context
$x:A,y:B,z:C,w:D$ with the term $(x \odot y) \times (z \odot w)$
describing the tree.  Because the context descriptors are themselves
ordinary structural/cartesian terms, the same variable can occur more
than once or not at all.  A descriptor such as $x \odot x$ captures the
idea that we can use the \emph{same} variable $x$ twice, expressing
$n$-linear types.  Thus, we can express contraction for a particular
context descriptor $\odot$ as a transformation $x \spr x \odot x$ (one
use of $x$ allows two).  Weakening, on the other hand, is represented by
a transformation $x \spr 1$, which is oriented to allow throwing away an
allowed use of $x$, but not creating an allowed use from nothing.  We
refer to these as \emph{structural transformations}, to evoke their use
in representing the structural properties of object logics that are
embedded in our framework.  The main sequent $\seq{\Gamma}{\alpha}{A}$
respects the specified structural properties in the sense that when
$\alpha = \beta$, we regard $\seq{\Gamma}{\alpha}{A}$ and
$\seq{\Gamma}{\beta}{A}$ as the same sequent, while when $\alpha \spr
\beta$, there will be an operation that takes a derivation of
\seq{\Gamma}{\beta}{A} to a derivation of \seq{\Gamma}{\alpha}{A}.

Modal logics will generally involve a mode theory with more than one
mode.  For example, a context descriptor $x : \dsd{c} \vdash \dsd{f}(x)
: \dsd{l}$ will generate an adjoint pair of functors between the two
modes, as in the adjoint syntax for linear logic's
$!$~\citep{bentonwadler96adjoint} or other modal
operators~\citep{reed09adjoint}.  Structural transformations are used to
describe how these modal operators interact with each other and with the
product structures, and in some cases~\citep{ls16adjoint} it is
important that there can be more than one structural transformation
between a given pair of context descriptors.

A guiding principle of the framework is a meta-level notion of
\emph{structurality over structurality}.  For example, we always have
\emph{weakening over weakening}: if \seq{\Gamma}{\alpha}{A} then
\seq{\Gamma,y:B}{\alpha}{A}, where $\alpha$ itself is weakened with $y$.
This does not prevent encodings of e.g. linear logic: it is permissible
to weaken a derivation of \seq{\Gamma}{x_1 \odot \ldots \odot x_n}{A}
(``use $x_1$ through $x_n$'') to a derivation of \seq{\Gamma,y:B}{x_1
  \odot \ldots \odot x_n}{A} because the (weakened) context descriptor
still disallows the use of $y$.  Similarly, we have exchange over
exchange and contraction over contraction.  The \emph{identity-over-identity}
principle says that we should be able to prove $A$ using exactly an
assumption $x:A$ ({\seq{\Gamma,x:A}{x}{A}}).  The cut principle says
that from \seq{\Gamma,x:A}{\beta}{B} and \seq{\Gamma}{\alpha}{A} we get
{\seq{\Gamma}{\subst{\beta}{\alpha}{x}}{B}}---the context descriptor for
the result of the cut is the substitution of the context descriptor used
to prove $A$ into the one used to prove $B$.  For example, together with
weakening-over-weakening, this captures the usual cut principle of
linear logic, which says that cutting $\Gamma,x:A \vdash B$ and $\Delta
\vdash A$ yields $\Gamma,\Delta \vdash B$.  If $\Gamma$ binds
$x_1,\ldots,x_n$ and $\Delta$ binds $y_1,\ldots,y_n$, then we will
represent the two derivations to be cut together by sequents with $\beta
= x_1 \odot \ldots \odot x_n \odot x$ and $\alpha = y_1 \odot \ldots
\odot y_n$ then $\beta[\alpha/x] = x_1 \odot \ldots \odot x_n \odot y_1
\odot \ldots \odot y_n$ correctly deletes $x$ and replaces it with the
variables from $\Delta$.  In more subtle situations such as BI, the
substitution will insert the resources used to prove the cut formula in
the correct place in the tree.

The framework has two main logical connectives / type constructors.  The
first, \F{\alpha}{\Delta}, generalizes the \dsd{F} of adjoint logic and
the multiplicative products (e.g. $\otimes$ of linear logic).  The
second, \U{x.\alpha}{\Delta}{A}, generalizes the $\dsd{G}/\dsd{U}$ of
adjoint logic and implication (e.g. $A \lolli B$ in linear logic).  Here
$\Delta$ is a context of assumptions $x_i:A_i$, and trivializing the
context descriptors (i.e. adding an equation $\alpha = \beta$ for all
$\alpha$ and $\beta$) degenerates $\F{\alpha}{\Delta}$ into the ordinary
intuitionistic product $A_1 \times \ldots \times A_n$, while
\U{x.\alpha}{\Delta}{A} becomes $A_1 \to \ldots \to A_n \to A$.  
As one would expect, \dsd{F} is left-invertible and \dsd{U} is right-invertible.
%%  and we conjecture that focusing works with the
%% polarization that one would expect based on these degeneracies
%% ($\F{\alpha}{\Delta^{\mathord{+}}}^{\mathord{+}}$ and
%% $\U{x.\alpha}{\Delta^{\mathord{+}}}{A^{\mathord{-}}}^{\mathord{-}}$).
In linear logic terms, our \dsd{F} and \dsd{U} cover both the
multiplicatives and exponentials; additives can be added separately by
the usual rules.  We discuss many examples of \emph{logical adequacy}
theorems, showing that a sequent can be proved in a standard sequent
calculus for a logic iff its embedding using these connectives can be
proved in the framework.

%% In summary, to specify a particular substructural or modal logic / type
%% theory, one gives constants generating context descriptors $\alpha$,
%% with equations $\alpha = \beta$ and transformations $\alpha \spr \beta$
%% expressing structural properties.  

Being a very general theory, our framework treats the object-logic
structural properties in a general but na\"ive way, allowing an
arbitrary structural transformation to be applied at the non-invertible
rules for $\dsd{F}$ and $\dsd{U}$ and at the leaves of a derivation.
For specific embedded logics, there is often a more refined discipline
that suffices---e.g. for cartesian logic, always contract all
assumptions in all premises, and only weaken at the leaves.  We view our
framework as a tool for bridging the gap between an intended semantic
situation (such as the cohesion example mentioned, ``a comonad and a
monad which are themselves adjoint'') and a proof theory: the framework
gives \emph{some} proof theory for the semantics, and the placement of
structural rules can then be optimized purely in syntax.  To support
this mode of use, we give an equational theory on sequent derivations
that identifies different placements of the same structural rules, which
can be used to prove correctness of such optimizations not just at the
level of provability, but also identity of derivations---which matters
for our intended applications to internal languages.  We discuss some
preliminary work on \emph{equational adequacy}, which extends the
logical correspondence to isomorphisms of definitional-equality-classes
of derivations.

Semantically, the logic corresponds to a functor between
\emph{2-dimensional cartesian multicategories} which is a fibration in
various senses.  Multicategories are a generalization of categories
which allow more than one object in the domain, and cartesianness means
that the multiple domain objects are treated structurally.  The
2-dimensionality supplies a notion of morphism between (multi)morphisms.
A \emph{mode theory} specifying context descriptors and structural
properties is analyzed as a cartesian 2-multicategory, with the
descriptors as 1-cells and the structural properties as 2-cells.  The
functor relates the sequent judgement to the mode theory, specifying the
mode of each proposition and the context descriptor of a sequent.  The
fibration conditions (similar to
\citep{hermida02fibrations,hormann15multicategories}) give respect for
the structural transformations and the presence of \dsd{F} and \dsd{U}
types.  We prove that the sequent calculus and the equational theory are
sound and complete for this semantics: the syntax can be interpreted in
any bifibration, and itself determines one.  This semantics shows that
an interesting class of type theories can be identified with a class of
more mathematical objects, fibrations of cartesian 2-multicategories,
thus providing some progress towards characterizing substructural
and modal type theories in mathematical terms.

\ifthenelse{\boolean{short}}{}{\input{related}}

%% Similar semantic structures have come up recently
%% in~\citep{zeilberger,mellieszeilberger,johann}.  
 
